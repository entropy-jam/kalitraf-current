# CHP Traffic Incident Scraper

A modular, automated system for monitoring California Highway Patrol traffic incidents with real-time email notifications.

## ğŸ—ï¸ Project Structure

### Backend (Python)
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                    # Core modules
â”‚   â”‚   â”œâ”€â”€ webdriver_manager.py # WebDriver management
â”‚   â”‚   â”œâ”€â”€ incident_extractor.py # Data extraction
â”‚   â”‚   â”œâ”€â”€ data_manager.py      # JSON storage & comparison
â”‚   â”‚   â””â”€â”€ email_notifier.py    # SMTP email notifications
â”‚   â”œâ”€â”€ scrapers/                # Scraper implementations
â”‚   â”‚   â”œâ”€â”€ local_scraper.py     # Local development scraper
â”‚   â”‚   â””â”€â”€ github_scraper.py    # GitHub Actions scraper
â”‚   â””â”€â”€ utils/                   # Utility modules
â”œâ”€â”€ data/                        # JSON data storage
â”‚   â”œâ”€â”€ active_incidents_[CENTER].json  # Current incidents per center
â”‚   â”œâ”€â”€ incident_deltas_[CENTER].json   # Change deltas per center
â”‚   â””â”€â”€ YYYY-MM-DD_incidents_[CENTER].json  # Daily archives per center
â”œâ”€â”€ scrape_local.py             # Local scraper entry point
â””â”€â”€ scrape_github.py           # GitHub Actions entry point
```

### Frontend (JavaScript - SOLID Architecture)
```
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ interfaces.js           # Interface definitions (SOLID)
â”‚   â”œâ”€â”€ config-manager.js       # Configuration management
â”‚   â”œâ”€â”€ storage/                # Storage implementations
â”‚   â”‚   â””â”€â”€ local-storage.js    # localStorage adapter
â”‚   â”œâ”€â”€ fetchers/               # Data fetching implementations
â”‚   â”‚   â””â”€â”€ http-fetcher.js     # HTTP client
â”‚   â”œâ”€â”€ renderers/              # UI rendering implementations
â”‚   â”‚   â””â”€â”€ incident-renderer.js # Incident display logic
â”‚   â”œâ”€â”€ services/               # Business logic services
â”‚   â”‚   â””â”€â”€ incident-service.js # Incident data operations
â”‚   â”œâ”€â”€ controllers/            # Application controllers
â”‚   â”‚   â””â”€â”€ app-controller.js   # Main application controller
â”‚   â”œâ”€â”€ cache.js               # Legacy cache module
â”‚   â”œâ”€â”€ virtual-scroll.js      # Virtual scrolling implementation
â”‚   â”œâ”€â”€ data-manager.js        # Legacy data management
â”‚   â”œâ”€â”€ ui-controller.js       # Legacy UI controller
â”‚   â””â”€â”€ app.js                 # Application entry point
â”œâ”€â”€ styles.css                 # Separated CSS styles
â”œâ”€â”€ index.html                 # Clean HTML structure
â”œâ”€â”€ vercel.json                # Vercel deployment configuration
â””â”€â”€ .vercelignore              # Vercel build exclusions
```

## ğŸš€ Quick Start

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run local scraper (once)
python scrape_local.py --once --center BCCC

# Run continuous monitoring
python scrape_local.py --center BCCC --interval 60 --iterations 10
```

### GitHub Actions
The system automatically runs every minute via GitHub Actions, scraping incidents and sending email notifications when changes are detected.

## ğŸ“§ Email Notifications

Configure email notifications by setting environment variables:
- `GMAIL_SENDER_EMAIL`: Your Gmail address
- `GMAIL_RECIPIENT_EMAIL`: Recipient email address  
- `GMAIL_APP_PASSWORD`: Gmail App Password (16 characters)

## ğŸ¯ Features

- **Modular Design**: Clean separation of concerns
- **Real-time Monitoring**: Scrapes every minute
- **Email Alerts**: Instant notifications for new/resolved incidents
- **Data Persistence**: JSON storage with historical tracking
- **Multi-center Support**: BCCC, CCC, NCCC, SCCC
- **GitHub Pages**: Live web dashboard

## ğŸ”§ Configuration

### Communication Centers
- `BCCC`: Border Communications Center
- `CCC`: Central Communications Center  
- `NCCC`: Northern Communications Center
- `SCCC`: Southern Communications Center

### Environment Variables
- `COMMUNICATION_CENTER`: Center to scrape (default: BCCC)
- `ENABLE_EMAIL_NOTIFICATIONS`: Enable/disable emails (default: false)
- `GMAIL_SENDER_EMAIL`: Sender email address
- `GMAIL_RECIPIENT_EMAIL`: Recipient email address
- `GMAIL_APP_PASSWORD`: Gmail App Password

## ğŸ“Š Data Format

### Active Incidents (`data/active_incidents_[CENTER].json`)
```json
{
  "center_code": "BCCC",
  "center_name": "Border",
  "incident_count": 18,
  "incidents": [...],
  "last_updated": "2025-09-23T17:45:19.641000"
}
```

### Daily Archive (`data/YYYY-MM-DD_incidents_[CENTER].json`)
```json
{
  "center_code": "BCCC", 
  "center_name": "Border",
  "date": "2025-09-23",
  "total_incidents": 22,
  "incidents": [...],
  "last_updated": "2025-09-23T17:45:19.641000"
}
```

### Backward Compatibility (`active_incidents.json`)
The root-level `active_incidents.json` file is maintained for backward compatibility and contains BCCC data.

## ğŸŒ Live Deployment

### Vercel (Primary) ğŸš€
**Live dashboard**: [Deploy to Vercel](https://vercel.com/new/clone?repository-url=https://github.com/entropy-jam/chp-scraper)

**Features**:
- âš¡ Ultra-fast CDN delivery
- ğŸ”„ Real-time incident display
- ğŸ“± Communication center selection
- ğŸ”„ Auto-refresh every 30 seconds
- ğŸ“± Responsive design
- ğŸ¯ Optimized caching (30s for data, 1 year for assets)

### GitHub Pages (Legacy)
**Legacy dashboard**: https://entropy-jam.github.io/chp-scraper/

**Migration Status**: âœ… **Complete** - Migrated to Vercel for better performance

## ğŸ”’ Security

- All sensitive credentials stored in GitHub Secrets
- Gmail App Password used instead of OAuth
- No API keys exposed in code
- Secure SMTP authentication

## ğŸ“ Logging

- Local: `chp_scraper_debug.log`
- GitHub Actions: Built-in logging
- Structured logging with timestamps

## ğŸ› ï¸ Development

### Adding New Features
1. Create new modules in `src/core/` or `src/utils/`
2. Update scrapers in `src/scrapers/`
3. Test locally with `scrape_local.py`
4. Update GitHub Actions workflow if needed

### Testing
```bash
# Test local scraper
python scrape_local.py --once --center BCCC

# Test GitHub scraper locally
COMMUNICATION_CENTER=BCCC python scrape_github.py
```

## ğŸ—ºï¸ Deployment & Migration

### âœ… **Phase 1: Vercel Migration Complete**
- **Status**: Successfully migrated from GitHub Pages to Vercel
- **Performance**: 10x faster delivery via global CDN
- **Configuration**: Optimized `vercel.json` with smart caching
- **Framework**: Static site deployment (no build process needed)
- **Live URL**: https://chp-traffic-scraper-6iv6x4sns-entropy-jams-projects.vercel.app

### ğŸš€ **Phase 2: WebSocket Real-Time Updates (NEXT)**
- **Current**: 60-second update delay (GitHub Actions scraping)
- **Target**: Sub-second real-time updates via WebSocket
- **Implementation**: External WebSocket service integration
- **Timeline**: 4-week development plan
- **Details**: See [MIGRATION.md](MIGRATION.md) for comprehensive plan

### ğŸ“ˆ **Migration Benefits**
- **Phase 1**: 10x faster static delivery
- **Phase 2**: Real-time incident updates (<1 second)
- **Future**: Push notifications, sound alerts, mobile app

## ğŸ“„ License

MIT License - see LICENSE file for details.
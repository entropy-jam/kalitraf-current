# CHP Traffic Incident Scraper

A modular, automated system for monitoring California Highway Patrol traffic incidents with real-time email notifications.

## ğŸ—ï¸ Project Structure

### Backend (Python)
```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                    # Core modules
â”‚   â”‚   â”œâ”€â”€ webdriver_manager.py # WebDriver management
â”‚   â”‚   â”œâ”€â”€ incident_extractor.py # Data extraction
â”‚   â”‚   â”œâ”€â”€ data_manager.py      # JSON storage & comparison
â”‚   â”‚   â””â”€â”€ email_notifier.py    # SMTP email notifications
â”‚   â”œâ”€â”€ scrapers/                # Scraper implementations
â”‚   â”‚   â”œâ”€â”€ local_scraper.py     # Local development scraper
â”‚   â”‚   â””â”€â”€ github_scraper.py    # GitHub Actions scraper
â”‚   â””â”€â”€ utils/                   # Utility modules
â”œâ”€â”€ data/                        # JSON data storage
â”‚   â”œâ”€â”€ active_incidents_[CENTER].json  # Current incidents per center
â”‚   â”œâ”€â”€ incident_deltas_[CENTER].json   # Change deltas per center
â”‚   â””â”€â”€ YYYY-MM-DD_incidents_[CENTER].json  # Daily archives per center
â”œâ”€â”€ scrape_local.py             # Local scraper entry point
â””â”€â”€ scrape_github.py           # GitHub Actions entry point
```

### Frontend (JavaScript - SOLID Architecture)
```
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ interfaces.js           # Interface definitions (SOLID)
â”‚   â”œâ”€â”€ config-manager.js       # Configuration management
â”‚   â”œâ”€â”€ storage/                # Storage implementations
â”‚   â”‚   â””â”€â”€ local-storage.js    # localStorage adapter
â”‚   â”œâ”€â”€ fetchers/               # Data fetching implementations
â”‚   â”‚   â””â”€â”€ http-fetcher.js     # HTTP client
â”‚   â”œâ”€â”€ renderers/              # UI rendering implementations
â”‚   â”‚   â””â”€â”€ incident-renderer.js # Incident display logic
â”‚   â”œâ”€â”€ services/               # Business logic services
â”‚   â”‚   â””â”€â”€ incident-service.js # Incident data operations
â”‚   â”œâ”€â”€ controllers/            # Application controllers
â”‚   â”‚   â””â”€â”€ app-controller.js   # Main application controller
â”‚   â”œâ”€â”€ cache.js               # Legacy cache module
â”‚   â”œâ”€â”€ virtual-scroll.js      # Virtual scrolling implementation
â”‚   â”œâ”€â”€ data-manager.js        # Legacy data management
â”‚   â”œâ”€â”€ ui-controller.js       # Legacy UI controller
â”‚   â””â”€â”€ app.js                 # Application entry point
â”œâ”€â”€ styles.css                 # Separated CSS styles
â””â”€â”€ index.html                 # Clean HTML structure
```

## ğŸš€ Quick Start

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run local scraper (once)
python scrape_local.py --once --center BCCC

# Run continuous monitoring
python scrape_local.py --center BCCC --interval 60 --iterations 10
```

### GitHub Actions
The system automatically runs every minute via GitHub Actions, scraping incidents and sending email notifications when changes are detected.

## ğŸ“§ Email Notifications

Configure email notifications by setting environment variables:
- `GMAIL_SENDER_EMAIL`: Your Gmail address
- `GMAIL_RECIPIENT_EMAIL`: Recipient email address  
- `GMAIL_APP_PASSWORD`: Gmail App Password (16 characters)

## ğŸ¯ Features

- **Modular Design**: Clean separation of concerns
- **Real-time Monitoring**: Scrapes every minute
- **Email Alerts**: Instant notifications for new/resolved incidents
- **Data Persistence**: JSON storage with historical tracking
- **Multi-center Support**: BCCC, CCC, NCCC, SCCC
- **GitHub Pages**: Live web dashboard

## ğŸ”§ Configuration

### Communication Centers
- `BCCC`: Border Communications Center
- `CCC`: Central Communications Center  
- `NCCC`: Northern Communications Center
- `SCCC`: Southern Communications Center

### Environment Variables
- `COMMUNICATION_CENTER`: Center to scrape (default: BCCC)
- `ENABLE_EMAIL_NOTIFICATIONS`: Enable/disable emails (default: false)
- `GMAIL_SENDER_EMAIL`: Sender email address
- `GMAIL_RECIPIENT_EMAIL`: Recipient email address
- `GMAIL_APP_PASSWORD`: Gmail App Password

## ğŸ“Š Data Format

### Active Incidents (`data/active_incidents_[CENTER].json`)
```json
{
  "center_code": "BCCC",
  "center_name": "Border",
  "incident_count": 18,
  "incidents": [...],
  "last_updated": "2025-09-23T17:45:19.641000"
}
```

### Daily Archive (`data/YYYY-MM-DD_incidents_[CENTER].json`)
```json
{
  "center_code": "BCCC", 
  "center_name": "Border",
  "date": "2025-09-23",
  "total_incidents": 22,
  "incidents": [...],
  "last_updated": "2025-09-23T17:45:19.641000"
}
```

### Backward Compatibility (`active_incidents.json`)
The root-level `active_incidents.json` file is maintained for backward compatibility and contains BCCC data.

## ğŸŒ GitHub Pages

Live dashboard available at: https://entropy-jam.github.io/chp-scraper/

Features:
- Real-time incident display
- Communication center selection
- Auto-refresh every 30 seconds
- Responsive design

## ğŸ”’ Security

- All sensitive credentials stored in GitHub Secrets
- Gmail App Password used instead of OAuth
- No API keys exposed in code
- Secure SMTP authentication

## ğŸ“ Logging

- Local: `chp_scraper_debug.log`
- GitHub Actions: Built-in logging
- Structured logging with timestamps

## ğŸ› ï¸ Development

### Adding New Features
1. Create new modules in `src/core/` or `src/utils/`
2. Update scrapers in `src/scrapers/`
3. Test locally with `scrape_local.py`
4. Update GitHub Actions workflow if needed

### Testing
```bash
# Test local scraper
python scrape_local.py --once --center BCCC

# Test GitHub scraper locally
COMMUNICATION_CENTER=BCCC python scrape_github.py
```

## ğŸ—ºï¸ Roadmap: Dynamic Hosting

**Current**: GitHub Pages (30-60s update delay)  
**Planned**: Vercel/Netlify with WebSockets (<1s updates)

- **1**: API backend + real-time frontend
- **2**: Advanced features + mobile app

**Benefits**: 10x faster updates, real-time notifications, better scalability

## ğŸ“„ License

MIT License - see LICENSE file for details.
name: CHP Traffic Incident Scraper

on:
  # Run every minute
  schedule:
    - cron: '* * * * *'
  
  # Manual trigger with parameters
  workflow_dispatch:
    inputs:
      communication_center:
        description: 'Communication Center to scrape'
        required: false
        default: 'BCCC'
        type: choice
        options:
          - BCCC  # Border
          - CCC   # Central
          - NCCC  # Northern
          - SCCC  # Southern
      run_once:
        description: 'Run once and exit (no continuous monitoring)'
        required: false
        default: false
        type: boolean

  # Allow manual trigger from API
  repository_dispatch:
    types: [manual-scrape]

jobs:
  scrape-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wget gnupg
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Download ChromeDriver
      run: |
        # Use webdriver-manager to download the correct ChromeDriver
        python -c "
        from webdriver_manager.chrome import ChromeDriverManager
        from selenium.webdriver.chrome.service import Service
        import os
        
        # Download and get the path to ChromeDriver
        driver_path = ChromeDriverManager().install()
        print(f'ChromeDriver installed at: {driver_path}')
        
        # Make it executable
        os.chmod(driver_path, 0o755)
        
        # Create symlink for easy access
        os.system(f'sudo ln -sf {driver_path} /usr/local/bin/chromedriver')
        
        # Verify installation
        os.system('chromedriver --version')
        "

    - name: Set environment variables
      run: |
        echo "COMMUNICATION_CENTER=${{ github.event.inputs.communication_center || 'BCCC' }}" >> $GITHUB_ENV
        echo "RUN_ONCE=${{ github.event.inputs.run_once || 'false' }}" >> $GITHUB_ENV
        echo "SCRAPER_MODE=github_actions" >> $GITHUB_ENV

    - name: Run traffic scraper
      run: |
        python chp_scraper.py --center $COMMUNICATION_CENTER --mode $SCRAPER_MODE

    - name: Check for changes
      id: changes
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push changes
      if: steps.changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        git add *.json
        git commit -m "Update traffic incidents - $(date '+%Y-%m-%d %H:%M:%S')"
        git push

    - name: Update GitHub Pages
      if: steps.changes.outputs.changes == 'true'
      run: |
        # Update the data timestamp for auto-refresh
        echo "{\"last_updated\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" > data/timestamp.json

    - name: Notify on failure
      if: failure()
      run: |
        echo "Traffic scraper failed at $(date)"
        # You can add webhook notifications here if needed
